{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You have to mention the same format of your image file in the code(eg:-.jpg/.png/.jpeg/.tif etc.)\n",
    "input_image = cv2.imread('E:\\\\cv2_image\\\\road.jpeg')\n",
    "cv2.imshow('road', input_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 259, 3)\n"
     ]
    }
   ],
   "source": [
    "print(input_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let convert our color image to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load our input image\n",
    "image = cv2.imread('E:\\\\cv2_image\\\\road.jpeg')\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey()\n",
    "\n",
    "# We use cvtColor, to convert to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Grayscale', gray_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another method faster method\n",
    "img = cv2.imread('E:\\\\cv2_image\\\\road.jpeg',0)\n",
    "\n",
    "cv2.imshow('Grayscale', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge Detection & Image Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('E:\\\\cv2_image\\\\road.jpeg',0)\n",
    "\n",
    "Height, Width = image.shape\n",
    "\n",
    "# Extract Sobel Edges\n",
    "sobel_x = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "sobel_y = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel X', sobel_x)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel Y', sobel_y)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "sobel_OR = cv2.bitwise_or(sobel_x, sobel_y)\n",
    "cv2.imshow('sobel_OR', sobel_OR)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "canny = cv2.Canny(image, 50, 120)\n",
    "cv2.imshow('Canny', canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translations\n",
    "\n",
    "This an affine transform that simply shifts the position of an image.\n",
    "\n",
    "We use cv2.warpAffine to implement these transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('E:\\\\cv2_image\\\\road.jpeg')\n",
    "\n",
    "# Store height and width of the image\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "quarter_height, quarter_width = height/4, width/4\n",
    "\n",
    "T = np.float32([[1, 0, quarter_width], [0, 1,quarter_height]])\n",
    "\n",
    "img_translation = cv2.warpAffine(image, T, (width, height))\n",
    "cv2.imshow('Translation', img_translation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('E:\\\\cv2_image\\\\road.jpeg')\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Divide by two to rotate the image around its centre\n",
    "rotation_matrix = cv2.getRotationMatrix2D((width/2, height/2), 45, .5)\n",
    "\n",
    "rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
    "\n",
    "cv2.imshow('Rotated Image', rotated_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets now to a horizontal flip.\n",
    "flipped = cv2.flip(image, 1)\n",
    "cv2.imshow('Horizontal Flip', flipped)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling, Re-sizing and Interpolations\n",
    "\n",
    "Re-sizing is very easy using the cv2.resize function, it is arguments are:\n",
    "\n",
    "cv2.resize(image, dsize(output image size), x scale, y scale, interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load our input image\n",
    "image = cv2.imread('E:\\\\cv2_image\\\\road.jpeg')\n",
    "\n",
    "# Lets make our image 3/4 of its original size\n",
    "image_scaled = cv2.resize(image, None, fx=0.75, fy=0.75)\n",
    "cv2.imshow('Scaling - Linear Interpolation', image_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Let's double the size of our image\n",
    "img_scaled = cv2.resize(image, None, fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow('Scaling - Cubic Interpolation', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Let's skew the re-sizing by setting exact dimensions\n",
    "img_scaled = cv2.resize(image, (900, 400), interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('Scaling - Skewed Size', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Pyramids\n",
    "\n",
    "Useful when scaling images in object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('E:\\\\cv2_image\\\\road.jpeg')\n",
    "\n",
    "smaller = cv2.pyrDown(image)\n",
    "larger = cv2.pyrUp(smaller)\n",
    "\n",
    "cv2.imshow('Original', smaller)\n",
    "\n",
    "cv2.imshow('Smaller', smaller)\n",
    "cv2.imshow('Larger', larger)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('E:\\\\cv2_image\\\\road.jpeg')\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Let's get the starting pixel coordinates (top left of cropping rectangle)\n",
    "start_row, start_col = int(height * .25), int(width * .25)\n",
    "\n",
    "# Let's get the ending pixel coordinates (botton right)\n",
    "end_row, end_col = int(height * .75), int(width * .75)\n",
    "\n",
    "# Simply use indexing to crop out the rectangle we desire\n",
    "cropped = image[start_row:end_row , start_col:end_col]\n",
    "\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"Cropped Image\", cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arithmetic Operatons\n",
    "\n",
    "These are simple operations that allow us to directly add or subract to the color intensity.\n",
    "\n",
    "Calculates the per-element operation of two arrays. The overall effect is increasing or decreassing brightness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('E:\\\\cv2_image\\\\road.jpeg')\n",
    "\n",
    "# Create a matrix of ones, then multiply it by a scaler of 100\n",
    "# This gives a matrix with same dimensions of our image with all values being 100\n",
    "M = np.ones(image.shape, dtype = \"uint8\") * 75\n",
    "\n",
    "cv2.imshow(\"Original\", image)\n",
    "\n",
    "# we use this to add this matrix M, to our image\n",
    "# Notice the increase in brightness\n",
    "added = cv2.add(image, M)\n",
    "cv2.imshow(\"Added\", added)\n",
    "\n",
    "# Likewise we can also subtract\n",
    "# Notice the decrease in brightness\n",
    "subtracted = cv2.subtract(image, M)\n",
    "cv2.imshow(\"Subtracted\", subtracted)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sharpening\n",
    "\n",
    "By altering our kernels we can implement sharpening, which has the effects of in strengthening or emphasizing edges in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('E:\\\\cv2_image\\\\road.jpeg')\n",
    "cv2.imshow('Original', image)\n",
    "\n",
    "kernel_sharpening = np.array([[-1,-1,-1],\n",
    "                              [-1,10,-1],\n",
    "                              [-1,-1,-1]])\n",
    "\n",
    "# applying different kernels to the input image\n",
    "sharpened = cv2.filter2D(image, -1, kernel_sharpening)\n",
    "\n",
    "cv2.imshow('Image Sharpening', sharpened)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('E:\\\\cv2_image\\\\road.jpeg')\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Creating our 3 x 3 kernel\n",
    "kernel_3x3 = np.ones((3, 3), np.float32) / 9\n",
    "\n",
    "# We use the cv2.filter2D to conovlve the kernel with an image\n",
    "blurred = cv2.filter2D(image, -1, kernel_3x3)\n",
    "cv2.imshow('3x3 Kernel Blurring', blurred)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Creating our 7x7 kernel\n",
    "kernel_7x7 = np.ones((7, 7), np.float32) / 49\n",
    "\n",
    "blurred2 = cv2.filter2D(image, -1, kernel_7x7)\n",
    "cv2.imshow('7x7 Kernel Blurring', blurred2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('E:\\\\cv2_image\\\\road.jpeg')\n",
    "\n",
    "# Averaging done by convolving the image with a normalized box filter.\n",
    "# This takes the pixels under the box and replaces the contral element\n",
    "# Box size needs to add and positive\n",
    "blur = cv2.blur(image, (3,3))\n",
    "cv2.imshow('Averaging', blur)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Instead of box filter, gaussian kernel\n",
    "Gaussian = cv2.GaussianBlur(image, (7,7), 0)\n",
    "cv2.imshow('Gaussian Blurring', Gaussian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Takes median of all the pixels under kernel area and cetral\n",
    "# Element is replaced with this median value\n",
    "median = cv2.medianBlur(image, 5)\n",
    "cv2.imshow('Median Blurring', median)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Bilateral is very effective in noise removal while keeping edges sharp\n",
    "bilateral = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "cv2.imshow('Bilateral Blurring', bilateral)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
